{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14478,
     "status": "ok",
     "timestamp": 1699078460592,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "bRkaDPh-J37-",
    "outputId": "0a847ee4-fbde-4b0e-cd83-a3cc7abb880b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.7.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/larrywu/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /Users/larrywu/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/larrywu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/larrywu/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import gensim.downloader as api\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# text pre-processing\n",
    "!pip install pyspellchecker\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "executionInfo": {
     "elapsed": 57767,
     "status": "ok",
     "timestamp": 1699078518353,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "sEEIE9S9PaRb",
    "outputId": "71add03b-1512-4874-a5e5-042a8532b932"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "neutral       8638\n",
      "worry         8459\n",
      "happiness     5209\n",
      "sadness       5165\n",
      "love          3842\n",
      "surprise      2187\n",
      "fun           1776\n",
      "relief        1526\n",
      "hate          1323\n",
      "empty          827\n",
      "enthusiasm     759\n",
      "boredom        179\n",
      "anger          110\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion                                               text\n",
       "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2     sadness                Funeral ceremony...gloomy friday...\n",
       "3  enthusiasm               wants to hang out with friends SOON!\n",
       "4     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drive.mount(\"/content/drive\")\n",
    "\n",
    "# file_path = \"/content/drive/MyDrive/Neural Network/data/text_emotion.csv\"\n",
    "file_path = \"./text_emotion.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data = data[['sentiment','content']]\n",
    "data = data.rename(columns={'sentiment': 'emotion', 'content': 'text'})\n",
    "\n",
    "print(data['emotion'].value_counts())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4kOCAyU2kPS"
   },
   "source": [
    "### Preprocessing the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1699078518353,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "SoaVJmGHuWNJ",
    "outputId": "8f49be00-8c12-4571-9178-2c105090e844"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                               text\n",
       "0        2  @tiffanylue i know  i was listenin to bad habi...\n",
       "1       10  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2       10                Funeral ceremony...gloomy friday...\n",
       "3        3               wants to hang out with friends SOON!\n",
       "4        8  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "data['emotion'] = le.fit_transform(data['emotion'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1699078518354,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "sqy9ZOYqVeCO"
   },
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'website', text)\n",
    "\n",
    "def clean_text(text):\n",
    "    ## Remove at(username)\n",
    "    pattern = r'@[^@\\s]+'\n",
    "    text = re.sub(pattern, '', text)\n",
    "\n",
    "    ## Remove punctuations\n",
    "    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', text)\n",
    "    text = text.replace('؛',\"\", )\n",
    "\n",
    "    ## remove extra whitespace\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text =  \" \".join(text.split())\n",
    "    return text.strip()\n",
    "\n",
    "def correct_word(word):\n",
    "    corrected_word = spell.correction(word)\n",
    "\n",
    "    if corrected_word is not None:\n",
    "        return corrected_word\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "  # Look into custom tokenizer later\n",
    "  words = nltk.word_tokenize(text)\n",
    "  correct_words = []\n",
    "  for word in words:\n",
    "    # Perform spelling correction\n",
    "    corrected_word = correct_word(word)\n",
    "\n",
    "    correct_words.append(corrected_word)\n",
    "\n",
    "  return \" \".join(correct_words)\n",
    "\n",
    "def normalize_text(text):\n",
    "  text = remove_urls(text)\n",
    "  text = clean_text(text)\n",
    "  # text = preprocess_text(text)\n",
    "  return text\n",
    "\n",
    "def tokenize(text):\n",
    "  # Look into custom tokenizer later\n",
    "  return nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6185,
     "status": "ok",
     "timestamp": 1699078524530,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "6ulSd1LFfNVK",
    "outputId": "265dab81-8029-4d26-d53d-07c00b40a435"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>i know i was listenin to bad habit earlier and...</td>\n",
       "      <td>[i, know, i, was, listenin, to, bad, habit, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Layin n bed with a headache ughhhh waitin on y...</td>\n",
       "      <td>[Layin, n, bed, with, a, headache, ughhhh, wai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Funeral ceremony gloomy friday</td>\n",
       "      <td>[Funeral, ceremony, gloomy, friday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>wants to hang out with friends SOON</td>\n",
       "      <td>[wants, to, hang, out, with, friends, SOON]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>We want to trade with someone who has Houston ...</td>\n",
       "      <td>[We, want, to, trade, with, someone, who, has,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                               text  \\\n",
       "0        2  i know i was listenin to bad habit earlier and...   \n",
       "1       10  Layin n bed with a headache ughhhh waitin on y...   \n",
       "2       10                     Funeral ceremony gloomy friday   \n",
       "3        3                wants to hang out with friends SOON   \n",
       "4        8  We want to trade with someone who has Houston ...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [i, know, i, was, listenin, to, bad, habit, ea...  \n",
       "1  [Layin, n, bed, with, a, headache, ughhhh, wai...  \n",
       "2                [Funeral, ceremony, gloomy, friday]  \n",
       "3        [wants, to, hang, out, with, friends, SOON]  \n",
       "4  [We, want, to, trade, with, someone, who, has,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text = data.text.apply(lambda text : normalize_text(text))\n",
    "data['tokens'] = data.text.apply(lambda text : tokenize(text))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5E0FkgrfN_g"
   },
   "source": [
    "### Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 94913,
     "status": "ok",
     "timestamp": 1699078619438,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "t4hsekyffTHa"
   },
   "outputs": [],
   "source": [
    "# model_path = \"/content/drive/MyDrive/Neural Network/data/word2vec.bin\"\n",
    "model_path = \"./word2vec.bin\"\n",
    "model = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5589,
     "status": "ok",
     "timestamp": 1699078625024,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "5IT3tqD0gYp2",
    "outputId": "6a97fb97-2068-4fd1-c1bd-11ef228a3316"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('acquaintances', 0.7328366041183472),\n",
       " ('friend', 0.7098035216331482),\n",
       " ('buddies', 0.7023523449897766),\n",
       " ('pals', 0.6816098093986511),\n",
       " ('relatives', 0.6528787016868591)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_word(\"friends\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1699078625025,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "eOsa0EGngZ0K",
    "outputId": "7a251830-0cbd-4a5a-cb48-2f5b7673ced4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['friends'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1699078625025,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "VCC6pRTknASK",
    "outputId": "427c1665-4007-41fe-8d94-b16be2881860"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38405"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set()\n",
    "for tokens in data['tokens']:\n",
    "  for token in tokens:\n",
    "    vocab.add(token)\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 611,
     "status": "ok",
     "timestamp": 1699078625633,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "9OpR7koopIv3",
    "outputId": "414f562f-3fd5-4e68-ad74-25bd106bed2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words found: 29003 out of total of 38405 words\n"
     ]
    }
   ],
   "source": [
    "matrix_len = len(vocab) + 1 # extra word embedding for padding\n",
    "weights_matrix = np.zeros((matrix_len, 300))\n",
    "word2idx = {}\n",
    "words_found = 0\n",
    "\n",
    "words_missed = []\n",
    "for i, word in enumerate(vocab):\n",
    "  word2idx[word] = i+1\n",
    "  try:\n",
    "      weights_matrix[i+1] = model[word]\n",
    "      words_found += 1\n",
    "  except KeyError:\n",
    "      weights_matrix[i+1] = np.random.normal(scale=0.6, size=(300, ))\n",
    "      words_missed.append(word)\n",
    "\n",
    "print(f\"words found: {words_found} out of total of {len(vocab)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1699078625990,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "UUCcl2Yw5J4_",
    "outputId": "0e31a97a-60fa-46b9-863f-a159033a8753"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>i know i was listenin to bad habit earlier and...</td>\n",
       "      <td>[i, know, i, was, listenin, to, bad, habit, ea...</td>\n",
       "      <td>[36993, 37129, 36993, 34779, 38250, 36231, 301...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Layin n bed with a headache ughhhh waitin on y...</td>\n",
       "      <td>[Layin, n, bed, with, a, headache, ughhhh, wai...</td>\n",
       "      <td>[23034, 36560, 10185, 8914, 12793, 28797, 2637...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Funeral ceremony gloomy friday</td>\n",
       "      <td>[Funeral, ceremony, gloomy, friday]</td>\n",
       "      <td>[29581, 8824, 35250, 32243]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>wants to hang out with friends SOON</td>\n",
       "      <td>[wants, to, hang, out, with, friends, SOON]</td>\n",
       "      <td>[21484, 36231, 9351, 5063, 8914, 11483, 36799]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>We want to trade with someone who has Houston ...</td>\n",
       "      <td>[We, want, to, trade, with, someone, who, has,...</td>\n",
       "      <td>[13453, 19489, 36231, 30773, 8914, 32140, 3792...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                               text  \\\n",
       "0        2  i know i was listenin to bad habit earlier and...   \n",
       "1       10  Layin n bed with a headache ughhhh waitin on y...   \n",
       "2       10                     Funeral ceremony gloomy friday   \n",
       "3        3                wants to hang out with friends SOON   \n",
       "4        8  We want to trade with someone who has Houston ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [i, know, i, was, listenin, to, bad, habit, ea...   \n",
       "1  [Layin, n, bed, with, a, headache, ughhhh, wai...   \n",
       "2                [Funeral, ceremony, gloomy, friday]   \n",
       "3        [wants, to, hang, out, with, friends, SOON]   \n",
       "4  [We, want, to, trade, with, someone, who, has,...   \n",
       "\n",
       "                                             indices  \n",
       "0  [36993, 37129, 36993, 34779, 38250, 36231, 301...  \n",
       "1  [23034, 36560, 10185, 8914, 12793, 28797, 2637...  \n",
       "2                        [29581, 8824, 35250, 32243]  \n",
       "3     [21484, 36231, 9351, 5063, 8914, 11483, 36799]  \n",
       "4  [13453, 19489, 36231, 30773, 8914, 32140, 3792...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_to_sequence(tokens):\n",
    "  return [ word2idx[word] for word in tokens]\n",
    "\n",
    "data['indices'] = data['tokens'].apply(text_to_sequence)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1699078625991,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "Bys4yB898MUt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTqiAChP8NRJ"
   },
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1699078625991,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "ipvaqr2S_v2J",
    "outputId": "aa8f3ac1-73e6-4179-aa30-22ba2e09100a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>i know i was listenin to bad habit earlier and...</td>\n",
       "      <td>[i, know, i, was, listenin, to, bad, habit, ea...</td>\n",
       "      <td>[36993, 37129, 36993, 34779, 38250, 36231, 301...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Layin n bed with a headache ughhhh waitin on y...</td>\n",
       "      <td>[Layin, n, bed, with, a, headache, ughhhh, wai...</td>\n",
       "      <td>[23034, 36560, 10185, 8914, 12793, 28797, 2637...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Funeral ceremony gloomy friday</td>\n",
       "      <td>[Funeral, ceremony, gloomy, friday]</td>\n",
       "      <td>[29581, 8824, 35250, 32243, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>wants to hang out with friends SOON</td>\n",
       "      <td>[wants, to, hang, out, with, friends, SOON]</td>\n",
       "      <td>[21484, 36231, 9351, 5063, 8914, 11483, 36799,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>We want to trade with someone who has Houston ...</td>\n",
       "      <td>[We, want, to, trade, with, someone, who, has,...</td>\n",
       "      <td>[13453, 19489, 36231, 30773, 8914, 32140, 3792...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                               text  \\\n",
       "0        2  i know i was listenin to bad habit earlier and...   \n",
       "1       10  Layin n bed with a headache ughhhh waitin on y...   \n",
       "2       10                     Funeral ceremony gloomy friday   \n",
       "3        3                wants to hang out with friends SOON   \n",
       "4        8  We want to trade with someone who has Houston ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [i, know, i, was, listenin, to, bad, habit, ea...   \n",
       "1  [Layin, n, bed, with, a, headache, ughhhh, wai...   \n",
       "2                [Funeral, ceremony, gloomy, friday]   \n",
       "3        [wants, to, hang, out, with, friends, SOON]   \n",
       "4  [We, want, to, trade, with, someone, who, has,...   \n",
       "\n",
       "                                             indices  \n",
       "0  [36993, 37129, 36993, 34779, 38250, 36231, 301...  \n",
       "1  [23034, 36560, 10185, 8914, 12793, 28797, 2637...  \n",
       "2  [29581, 8824, 35250, 32243, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [21484, 36231, 9351, 5063, 8914, 11483, 36799,...  \n",
       "4  [13453, 19489, 36231, 30773, 8914, 32140, 3792...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_length = 32\n",
    "\n",
    "# Function to pad or truncate a sequence to the target length\n",
    "def pad_or_truncate(sequence):\n",
    "    if len(sequence) < target_length:\n",
    "        # Pad with zeros at the end if the sequence is shorter\n",
    "        return sequence + [0] * (target_length - len(sequence))\n",
    "    else:\n",
    "        # Truncate the sequence if it is longer\n",
    "        return sequence[:target_length]\n",
    "\n",
    "# Apply the function to the 'indices' column\n",
    "data['indices'] = data['indices'].apply(pad_or_truncate)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DVUr51zhChv"
   },
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1699078625991,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "XN4DCN3VqI73"
   },
   "outputs": [],
   "source": [
    "class TextEmotionDataset(Dataset):\n",
    "  def __init__(self, df):\n",
    "      self.indices = df['indices'].values\n",
    "      self.emotion = df['emotion'].values\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.emotion)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    indices = self.indices[idx]\n",
    "    emotion = self.emotion[idx]\n",
    "\n",
    "    indices = torch.tensor(indices, dtype=torch.int)\n",
    "\n",
    "    return indices, emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1699078626332,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "QrXW3gq0cbwu"
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data, test_size=0.1)\n",
    "\n",
    "train_dataset = TextEmotionDataset(train_df)\n",
    "test_dataset = TextEmotionDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNVIh4tKhHqa"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1699078626332,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "iGswRqVEAyTp",
    "outputId": "5b39fe4d-0b9f-4768-adf2-9675130bf8e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35378,  9729,  9729, 36791, 12793, 23486,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0], dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 300])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_layer = nn.Embedding.from_pretrained(torch.tensor(weights_matrix), padding_idx=0)\n",
    "input, output = train_loader.dataset[0]\n",
    "embedding = emb_layer(input)\n",
    "print(input)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1699078626333,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "l1YtZCvshMq7",
    "outputId": "99adbfd3-80da-48b4-f475-43410b6b7c36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (embedding): Embedding(38406, 300, padding_idx=0)\n",
       "  (lstm): LSTM(300, 128, batch_first=True, bidirectional=True)\n",
       "  (max_pooling): MaxPool1d(kernel_size=32, stride=32, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=256, out_features=13, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "  def __init__(self, hidden_dim, num_layers, num_classes, kernel_size=2, dropout_prob=0.2):\n",
    "    super().__init__()\n",
    "\n",
    "    self.embedding = nn.Embedding.from_pretrained(torch.tensor(weights_matrix, dtype=torch.float), padding_idx=0)\n",
    "    self.embedding_dim = 300\n",
    "    self.hidden_dim = hidden_dim\n",
    "\n",
    "    self.lstm = nn.LSTM(self.embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "    self.max_pooling = nn.MaxPool1d(kernel_size=target_length)\n",
    "    self.fc = nn.Linear(2*hidden_dim, num_classes)\n",
    "    self.dropout = nn.Dropout(p=dropout_prob)\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    embedded = self.embedding(x) # (batch, length of text, length of embedding)\n",
    "    out, _ = self.lstm(embedded) # (batch, length of text, 2 * hidden size)\n",
    "    out = out.permute(0, 2, 1)\n",
    "    out = self.max_pooling(out) # (batch, 2 * hidden size, 1)\n",
    "    out = out.reshape(-1, 2*self.hidden_dim)\n",
    "    out = self.dropout(out)\n",
    "    out = self.fc(out)\n",
    "    preds = self.softmax(out)\n",
    "\n",
    "    return preds\n",
    "\n",
    "model = TextClassificationModel(128, 1, 13)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "executionInfo": {
     "elapsed": 44478,
     "status": "error",
     "timestamp": 1699079163178,
     "user": {
      "displayName": "Larry",
      "userId": "00666647341852361937"
     },
     "user_tz": -480
    },
    "id": "D1x9eT5018NR",
    "outputId": "d00fa3a3-af94-42f7-be1c-cf02e9ed1a3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.009579474462403191\n",
      "tensor([12, 12, 12, 12,  8, 12, 12, 12, 12,  8, 12,  8, 12,  8, 12,  8,  8,  8,\n",
      "         8,  8,  8, 12, 12, 12,  8, 12, 12, 12,  8,  8,  8, 12,  8, 12, 12, 12,\n",
      "         8,  8, 12, 12,  8,  8,  8,  8,  8,  8,  8, 12, 12,  8, 12,  8,  8, 12,\n",
      "         8, 12, 12,  8, 12,  8,  8, 12,  8,  8,  8,  8,  8, 12,  8, 12, 12,  8,\n",
      "         8,  8, 12, 12,  8,  8,  8, 12, 12, 12, 12,  8, 12,  8, 12,  8, 12, 12,\n",
      "        12, 12,  8,  8, 12, 12,  8, 12,  8,  8,  8,  8, 12, 12, 12, 12,  8, 12,\n",
      "         8, 12, 12,  8,  8, 12,  8,  8, 12, 12,  8, 12,  8,  8, 12, 12, 12, 12,\n",
      "        12, 12, 12,  8, 12,  8, 12, 12, 12,  8, 12,  8,  8,  8,  8, 12, 12, 12,\n",
      "        12,  8,  8,  8, 12,  8,  8, 12,  8, 12, 12, 12, 12,  8, 12,  8,  8,  8,\n",
      "        12, 12,  8,  8,  8, 12,  8, 12,  8, 12,  8, 12, 12,  8,  8, 12, 12, 12,\n",
      "        12,  8, 12, 12,  8,  8,  8, 12,  8,  8,  8,  8,  8, 12,  8,  8, 12,  8,\n",
      "        12, 12, 12, 12, 12,  8,  8, 12,  8,  8, 12,  8,  8,  8, 12, 12,  8, 12,\n",
      "        12,  8, 12, 12, 12,  8,  8,  8,  8,  8, 12, 12, 12, 12,  8,  8,  8,  8,\n",
      "        12,  8, 12,  8,  8, 12, 12, 12,  8, 12, 12,  8, 12,  8,  8,  8, 12, 12,\n",
      "         8, 12, 12,  8])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     27\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m---> 28\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(h, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pred)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[28], line 17\u001b[0m, in \u001b[0;36mTextClassificationModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     16\u001b[0m   embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x) \u001b[38;5;66;03m# (batch, length of text, length of embedding)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m   out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (batch, length of text, 2 * hidden size)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m   out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_pooling(out) \u001b[38;5;66;03m# (batch, 2 * hidden size, 1)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "losses = []\n",
    "test_accuracies = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  loss_total, correct_total = 0, 0\n",
    "  model.train()\n",
    "\n",
    "\n",
    "  for x, y in train_loader:\n",
    "    optimizer.zero_grad()\n",
    "    h = model(x)\n",
    "    loss = criterion(h, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_total += loss.item()\n",
    "\n",
    "  losses.append(loss_total / len(train_loader.dataset))\n",
    "  print(f\"loss: {losses[-1]}\")\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "      h = model(x)\n",
    "      pred = torch.argmax(h, axis=1)\n",
    "      print(pred)\n",
    "      correct_total += (pred == y).float().sum().item()\n",
    "    test_accuracies.append(correct_total / len(test_loader.dataset))\n",
    "    print(f\"testing accuracy: {test_accuracies[-1]}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyPMicfE+HbdC57JWl4J2J5f",
   "mount_file_id": "1wZkYWGky4ISp6eEuSpPg1MfOhCNmBpUQ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
